{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modello_1_Hyperopt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqMJkhc8rg3g",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "4037ef82-ac20-4cb1-af5f-c0d534d481e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        }
      },
      "source": [
        "#@title Default title text\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__\n",
        "\n",
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "import os\n",
        "import csv\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from hyperopt import STATUS_OK\n",
        "from hyperopt import tpe, hp, Trials, fmin\n",
        "from IPython import display\n",
        "from matplotlib import pyplot\n",
        "from hyperopt import STATUS_OK\n",
        "from hyperopt import tpe, hp, Trials, fmin\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "with open('Original dataset/TrainOneCls.csv', 'r') as file:\n",
        "      data = {\"Xtrain\": pd.DataFrame(list(csv.DictReader(file))).astype(float), \"class\": 2}\n",
        "      data[\"Classification\"] = data[\"Xtrain\"]['Classification']\n",
        "      del data[\"Xtrain\"]['Classification']\n",
        "\n",
        "f_myfile = open('Test_LR/Pickle/train_10x10_MI.pickle', 'rb')\n",
        "data[\"img\"] = pickle.load(f_myfile)\n",
        "f_myfile.close()\n",
        "\n",
        "a=np.where(data[\"Classification\"]==0)\n",
        "\n",
        "train_images=np.array([data[\"img\"][index] for index in a[0]])\n",
        "print(len(train_images))\n",
        "train_images = train_images.reshape(train_images.shape[0], 10, 10, 1).astype('float32')\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 0\n",
        "optimizable_variable = {\"BATCH_SIZE\": hp.choice(\"BATCH_SIZE\", [64,128,256]),\n",
        "                        'dropout_rate': hp.uniform(\"dropout_rate\", 0, 1),  #Best PARAM = 0.3\n",
        "                        'lr_initial_g': hp.uniform(\"lr_initial_g\", 1e-2, 1e-4),   # 1e-4\n",
        "                        #'lr_initial_d': hp.uniform(\"lr_initial_d\", 1e-2, 1e-4)   # 1e-4\n",
        "                        #\"lr_initial_d\": hp.uniform(\"lr_initial_d\", 0.001, 0.0001)    # 1e-4\n",
        "                        }\n",
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "#dropout_rate=0.3\n",
        "\n",
        "# Batch and shuffle the data\n",
        "#train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "def make_generator_model(dropout_rate):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(noise_dim,)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def make_discriminator_model(dropout_rate):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss/2\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "def train_step(images,train_d,train_g,generator,discriminator,generator_optimizer,discriminator_optimizer):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    if train_d:\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    if train_g:\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def plot_history(d_hist, g_hist, step=0, is_global=False):\n",
        "    # plot loss\n",
        "    pyplot.subplot(2, 1, 1)\n",
        "    pyplot.plot(d_hist, label='d')\n",
        "    pyplot.plot(g_hist, label='gen')\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n",
        "\n",
        "total_step=0\n",
        "\n",
        "def opt(param):\n",
        "  global BATCH_SIZE\n",
        "  BATCH_SIZE=param[\"BATCH_SIZE\"]\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(param[\"BATCH_SIZE\"])\n",
        "  generator = make_generator_model(param[\"dropout_rate\"])\n",
        "\n",
        "  noise = tf.random.normal([1, 100])\n",
        "  discriminator = make_discriminator_model(param[\"dropout_rate\"])\n",
        "\n",
        "\n",
        "  generator_optimizer = tf.keras.optimizers.Adam(param[\"lr_initial_g\"])\n",
        "  param[\"lr_initial_d\"]=param[\"lr_initial_g\"]\n",
        "  discriminator_optimizer = tf.keras.optimizers.Adam(param[\"lr_initial_d\"])\n",
        "\n",
        "\n",
        "  loss,generator,discriminator=train(train_dataset, EPOCHS,generator,discriminator,generator_optimizer,discriminator_optimizer,param)\n",
        "  \n",
        "  noise = tf.random.normal([1024, 100])\n",
        "  predictions = generator(noise, training=False)\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  global total_step\n",
        "  for i in range(25):\n",
        "      plt.subplot(5, 5, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig(\"/content/drive/My Drive/gan mnist/results_no_error/img_\"+str(total_step)+\".png\")\n",
        "  plt.show()\n",
        "  #sottrazione media\n",
        "  errors =  - predictions\n",
        "  scalar_error=np.mean(np.mean(np.power(train_images[0:1024] - predictions, 2), axis=1))\n",
        "  print(scalar_error)\n",
        "  K.clear_session()\n",
        "  global res_error\n",
        "  res_error.append(param)\n",
        "  res_error[-1][\"error\"]=scalar_error\n",
        "  with open(\"/content/drive/My Drive/gan mnist/results_no_error/resError.csv\", 'w', newline='') as csvfile:\n",
        "          writer = csv.DictWriter(csvfile, fieldnames=res[0].keys())\n",
        "          writer.writeheader()\n",
        "          writer.writerows(res)\n",
        "  return {'loss': loss, 'status': STATUS_OK}\n",
        "\n",
        "\n",
        "  \n",
        "res=[]\n",
        "res_error=[]\n",
        "def train(dataset, epochs,generator,discriminator,generator_optimizer,discriminator_optimizer,param):\n",
        "  print(param)\n",
        "  global res\n",
        "  global total_step\n",
        "  res.append(param)\n",
        "  total_step=total_step+1\n",
        "  gen_ls=[]\n",
        "  disc_ls=[]\n",
        "  train_g=True\n",
        "  train_d=True\n",
        "  loss1=[]\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    gen=[]\n",
        "    disc=[]\n",
        "    for image_batch in dataset:\n",
        "      gen_loss, disc_loss= train_step(image_batch,train_d,train_g,generator,discriminator,generator_optimizer,discriminator_optimizer)\n",
        "      disc.append(disc_loss)\n",
        "      gen.append(gen_loss)\n",
        "\n",
        "    gen_ls.append(np.mean(gen))\n",
        "    disc_ls.append(np.mean(disc))\n",
        "    loss1.append(np.mean(gen)+np.mean(disc))\n",
        "    \n",
        "    with open(\"/content/drive/My Drive/gan mnist/results_no_error/res.csv\", 'w', newline='') as csvfile:\n",
        "          writer = csv.DictWriter(csvfile, fieldnames=res[0].keys())\n",
        "          writer.writeheader()\n",
        "          writer.writerows(res)\n",
        "    # Produce images for the GIF as we go\n",
        "    #display.clear_output(wait=True)\n",
        "\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "    plot_history(disc_ls,gen_ls)\n",
        "\n",
        "\n",
        "    if loss1[-1]==min(loss1):\n",
        "      print(\"new_best_model\")\n",
        "      res[-1].update({\"gen\":gen_ls[-1],\"disc\":disc_ls[-1]})\n",
        "\n",
        "      generator.save_weights(\"gen_\"+str(total_step)+\"_\"+str(epoch)+\".h5\")\n",
        "      discriminator.save_weights(\"disc_\"+str(total_step)+\"_\"+str(epoch)+\".h5\")\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    print(\"GEN:\"+str(train_g)+\" DISC\"+str(train_d))\n",
        "    print(\"GEN:\"+str( gen_ls[-1])+\" DISC\"+str( disc_ls[-1]))\n",
        "\n",
        "  # load best model\n",
        "  generator.load_weights(\"gen_\"+str(total_step)+\"_\"+str(np.argmin(loss1))+\".h5\")\n",
        "  discriminator.load_weights(\"disc_\"+str(total_step)+\"_\"+str(np.argmin(loss1))+\".h5\")\n",
        "  #result folder\n",
        "  generator.save_weights(\"/content/drive/My Drive/gan mnist/results_no_error/gen_\"+str(total_step)+\"_\"+str(epoch)+\".h5\")\n",
        "  discriminator.save_weights(\"/content/drive/My Drive/gan mnist/results_no_error/disc_\"+str(total_step)+\"_\"+str(epoch)+\".h5\")\n",
        "  \n",
        "   \n",
        "  return min(loss1),generator,discriminator\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "trials= Trials()\n",
        "print(optimizable_variable)\n",
        "newpath = r'results' \n",
        "if not os.path.exists(newpath):\n",
        "    os.makedirs(newpath)\n",
        "fmin(opt, optimizable_variable, algo=tpe.suggest, max_evals=20)\n",
        "\n",
        "\n",
        "#train(train_dataset, EPOCHS)\n",
        "\n",
        "\"\"\"Restore the latest checkpoint.\"\"\"\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "\"\"\"## Create a GIF\"\"\"\n",
        "\n",
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "display_image(EPOCHS)\n",
        "\n",
        "\"\"\"Use `imageio` to create an animated gif using the images saved during training.\"\"\"\n",
        "\n",
        "anim_file = 'dcgan.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "\n",
        "import IPython\n",
        "if IPython.version_info > (6,2,0,''):\n",
        "  display.Image(filename=anim_file)\n",
        "\n",
        "\"\"\"If you're working in Colab you can download the animation with the code below:\"\"\"\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "   pass\n",
        "else:\n",
        "  files.download(anim_file)\n",
        "\n",
        "\"\"\"## Next steps\n",
        "\n",
        "This tutorial has shown the complete code necessary to write and train a GAN. As a next step, you might like to experiment with a different dataset, for example the Large-scale Celeb Faces Attributes (CelebA) dataset [available on Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset). To learn more about GANs we recommend the [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160).\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.18.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (7.0.0)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "    8192/11490434 [..............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "{'BATCH_SIZE': <hyperopt.pyll.base.Apply object at 0x7f0ece568c50>, 'dropout_rate': <hyperopt.pyll.base.Apply object at 0x7f0ece568e48>, 'lr_initial_g': <hyperopt.pyll.base.Apply object at 0x7f0ece5980b8>}\n",
            "{'BATCH_SIZE': 128, 'dropout_rate': 0.8714440730715539, 'lr_initial_g': 0.0037854854458737198, 'lr_initial_d': 0.0037854854458737198}\n",
            "  0%|          | 0/20 [00:00<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "new_best_model\n",
            "Time for epoch 1 is 37.15104365348816 sec\n",
            "GEN:True DISCTrue\n",
            "GEN:6.644875 DISC0.34506083\n",
            "  0%|          | 0/20 [00:37<?, ?it/s, best loss: ?]"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}